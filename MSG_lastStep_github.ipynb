{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4be49b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T00:57:29.993273Z",
     "start_time": "2023-04-04T00:57:29.979988Z"
    }
   },
   "outputs": [],
   "source": [
    "# 导入相关包\n",
    "import math\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "#python在读写matlab文件时常用到scipy.io文件\n",
    "import scipy.io as sio\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense,BatchNormalization,LeakyReLU,Conv2DTranspose,Reshape,Conv2D,Dropout,Flatten,AveragePooling1D,Activation\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "import matplotlib\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras\n",
    "from scipy.signal import savgol_filter\n",
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83cfa28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T00:57:31.069727Z",
     "start_time": "2023-04-04T00:57:31.052850Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a4833",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T00:57:33.640451Z",
     "start_time": "2023-04-04T00:57:33.630579Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3f3bab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T08:12:04.703884Z",
     "start_time": "2023-04-04T08:12:04.666541Z"
    }
   },
   "outputs": [],
   "source": [
    "# os.chdir(r'D:\\大麦粉数据')\n",
    "x = np.load('trainx.npy',allow_pickle = True)\n",
    "y = np.load('trainy.npy',allow_pickle = True)\n",
    "axis_x = np.load('axis_x.npy',allow_pickle = True)\n",
    "#定义真实光谱数据\n",
    "wave = x.reshape(-1,2500)\n",
    "wave = wave.astype('float64')\n",
    "print(wave.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792c0ee3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T11:04:59.279752Z",
     "start_time": "2023-04-04T11:04:58.511445Z"
    }
   },
   "outputs": [],
   "source": [
    "def PlotSpectrum(spec,axis_x):\n",
    "    plt.figure(figsize=(5.2, 3.1), dpi=300)\n",
    "    x = axis_x\n",
    "    for i in range(spec.shape[0]):\n",
    "        plt.plot(x, spec[i, :], linewidth=0.6)\n",
    "    fonts = 8\n",
    "    plt.xlim(x.min(),x.max())\n",
    "    plt.ylim(0, 1)\n",
    "    # 设置刻度字体大小\n",
    "    plt.xlabel('Wavelength (nm)', fontsize=fonts)\n",
    "    plt.ylabel('absorbance (AU)', fontsize=fonts)\n",
    "    plt.yticks(fontsize=fonts)\n",
    "    plt.xticks(fontsize=fonts)\n",
    "    #Padding between the figure edge and the edges of subplots, as a fraction of the font size.\n",
    "    #调整方格\n",
    "    plt.tight_layout(pad=0.3)\n",
    "    #网格线设置\n",
    "    plt.grid(True)\n",
    "    return plt\n",
    "PlotSpectrum(wave,axis_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac15b684",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T11:04:58.043927Z",
     "start_time": "2023-04-04T11:04:58.043927Z"
    }
   },
   "outputs": [],
   "source": [
    "generator = tf.keras.models.load_model('MSG_generatorLast.h5')\n",
    "discriminator = tf.keras.models.load_model('MSG_discriminatorLast.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3917771",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T08:17:03.643424Z",
     "start_time": "2023-04-04T08:17:03.601728Z"
    }
   },
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6961db50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T08:56:44.931087Z",
     "start_time": "2023-04-04T08:56:44.911502Z"
    }
   },
   "outputs": [],
   "source": [
    "discriminator1 = Model(inputs=discriminator.input, \n",
    "                                 outputs=discriminator.get_layer(index=2).output)# 输出为1800，第2层\n",
    "\n",
    "discriminator2 = Model(inputs=discriminator.input, \n",
    "                                 outputs=discriminator.get_layer(index=5).output)# 输出为1800，第8层\n",
    "\n",
    "discriminator3 = Model(inputs=discriminator.input, \n",
    "                                 outputs=discriminator.get_layer(index=11).output)# 输出为1800，第8层\n",
    "\n",
    "discriminator4 = Model(inputs=discriminator.input, \n",
    "                                 outputs=discriminator.get_layer(index=14).output)# 输出为1800，第8层\n",
    "\n",
    "discriminator5 = Model(inputs=discriminator.input, \n",
    "                                 outputs=discriminator.get_layer(index=8).output)# 输出为500，最内层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff97d48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T08:57:02.233061Z",
     "start_time": "2023-04-04T08:57:02.226457Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "epochs = 6\n",
    "#定义一些常数\n",
    "lambda_k1=0.0002\n",
    "#k的初值设为：0\n",
    "k = tf.Variable(0.005,dtype=tf.float64)\n",
    "#设置gamma(高多样性好)\n",
    "gamma = tf.Variable(0.7,dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b83fa93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T08:57:02.681104Z",
     "start_time": "2023-04-04T08:57:02.666926Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义外层损失函数\n",
    "def L1(wave):\n",
    "    reconstituted_wave = discriminator(wave)# 输出D(G(x))\n",
    "    reconstituted_wave = tf.cast(reconstituted_wave,dtype=tf.float64)\n",
    "    loss1 = tf.reduce_mean(tf.abs(wave - reconstituted_wave))\n",
    "    return loss1\n",
    "def L2(noise):\n",
    "    generated_wave = generator(noise)# 通过生成器生成光谱generated_Spectrum\n",
    "    generated_wave = tf.cast(generated_wave,dtype=tf.float64)\n",
    "    reconstituted_generatedWave = discriminator(generated_wave)# 输出D(G(z))\n",
    "    reconstituted_generatedWave = tf.cast(reconstituted_generatedWave,dtype=tf.float64)\n",
    "    #作差-取绝对-求平均值(L(G(x)))\n",
    "    loss2 = tf.reduce_mean(tf.abs(reconstituted_generatedWave - generated_wave))\n",
    "    return loss2\n",
    "def outermost_of_G(noise):# 最外层的损失\n",
    "    loss = L2(noise)\n",
    "    return loss\n",
    "def outermost_of_D(wave, noise, k):# 最外层的损失\n",
    "    loss1 = L1(wave)\n",
    "    loss2 = L2(noise)\n",
    "    loss = loss1 - k*loss2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da488f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:28:30.258209Z",
     "start_time": "2023-04-04T10:28:30.247826Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义内层的损失函数（ReMix实现方式，通过分别给真实光谱X1,X2计算损失值，并给予不同权重）\n",
    "def mesosphere_L1(wave, model1, model2):# 输入真实光谱&每一层的判别模型\n",
    "    reconstituted_wave1 = model1(wave)# 输出D1(G(x))\n",
    "    reconstituted_wave1 = tf.cast(reconstituted_wave1,dtype=tf.float64)\n",
    "    reconstituted_wave2 = model2(wave)# 输出D2(G(x))\n",
    "    reconstituted_wave2 = tf.cast(reconstituted_wave2,dtype=tf.float64)    \n",
    "    # 输出D1(G(x)) - D2(G(x))\n",
    "    loss1 = tf.reduce_mean(tf.abs(reconstituted_wave1 - reconstituted_wave2))\n",
    "    return loss1\n",
    "def mesosphere_L2(noise, model1, model2):\n",
    "    generated_wave = generator(noise)# 通过生成器生成光谱generated_Spectrum\n",
    "    generated_wave = tf.cast(generated_wave,dtype=tf.float64)\n",
    "    reconstituted_generatedWave1 = model1(generated_wave)# 输出D1(G(z))\n",
    "    reconstituted_generatedWave1 = tf.cast(reconstituted_generatedWave1,dtype=tf.float64)\n",
    "    reconstituted_generatedWave2 = model2(generated_wave)# 输出D2(G(z))\n",
    "    reconstituted_generatedWave2 = tf.cast(reconstituted_generatedWave2,dtype=tf.float64)\n",
    "    #作差-取绝对-求平均值(L(G(x)))\n",
    "    loss2 = tf.reduce_mean(tf.abs(reconstituted_generatedWave1 - reconstituted_generatedWave2))  \n",
    "    return loss2\n",
    "def mesosphere_of_G(noise, model1, model2):# 内层的损失\n",
    "    loss = mesosphere_L2(noise, model1, model2)\n",
    "    return loss\n",
    "def mesosphere_of_D(noise, wave, model1, model2, k):# 内层的损失\n",
    "    loss1 = mesosphere_L1(wave, model1, model2)\n",
    "    loss2 = mesosphere_L2(noise, model1, model2)\n",
    "    loss = loss1 - k*loss2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e2c3d3",
   "metadata": {},
   "source": [
    "## 定义的ReMix：外层与MSGGAN一致，内层将以标签距离设置权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd1ec25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:33:09.364329Z",
     "start_time": "2023-04-04T10:33:09.356758Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义ReMix损失函数（最内层损失）\n",
    "def Innermost_L(wave1, wave2, noise, model, label, nearest_label):# 输入真实光谱&每一层的判别模型\n",
    "    generated_wave = generator(noise)# 通过生成器生成光谱generated_Spectrum\n",
    "    generated_wave = tf.cast(generated_wave,dtype=tf.float64)\n",
    "    reconstituted_wave = model(generated_wave)# 输出DInner(G(generated_wave))\n",
    "    reconstituted_wave = tf.cast(reconstituted_wave,dtype=tf.float64)\n",
    "    reconstituted_wave1 = model(wave1)# 输出DInner(G(wave1))\n",
    "    reconstituted_wave1 = tf.cast(reconstituted_wave1,dtype=tf.float64)\n",
    "    reconstituted_wave2 = model(wave2)# 输出DInner(G(wave2))\n",
    "    reconstituted_wave2 = tf.cast(reconstituted_wave2,dtype=tf.float64)\n",
    "    loss1 = tf.reduce_mean(tf.abs(reconstituted_wave - reconstituted_wave1))\n",
    "    loss2 = tf.reduce_mean(tf.abs(reconstituted_wave - reconstituted_wave2))\n",
    "    alpha = Calculated_weight(label, nearest_label)\n",
    "    loss = alpha*loss1 + (1 - alpha)*loss2\n",
    "    return loss1\n",
    "def Calculated_weight(label, nearest_label):\n",
    "    # alpha代表的是权重，值越大，权重越高，生成的理化值与该标签越近\n",
    "    differ = np.absolute(nearest_label - label)# 相减赋予绝对值\n",
    "    differSum = np.sum(differ)\n",
    "    if (differ == 0).any() == True:\n",
    "        if differ[0] == 0:# 该值为0时，则表明生成指标=第一个真实理化值，故权重要大\n",
    "            alpha = 1# 返回的是第一个光谱的权重\n",
    "            return alpha\n",
    "        else:\n",
    "            alpha = 0\n",
    "            return alpha\n",
    "    alpha = differ[1]/differSum\n",
    "    return alpha# 返回的是第一个光谱的权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f322006d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:33:09.555184Z",
     "start_time": "2023-04-04T10:33:09.545462Z"
    }
   },
   "outputs": [],
   "source": [
    "#定义总体进度函数\n",
    "def global_process(wave, noise, gamma):\n",
    "    loss1 = L1(wave)\n",
    "    loss2 = L2(noise)\n",
    "    balance = gamma*loss1 - loss2\n",
    "    balance = tf.cast(balance,dtype=tf.float64)\n",
    "    #总体进度定义\n",
    "    global_goal = loss1 + tf.abs(balance)\n",
    "    return global_goal, balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fee67a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:33:09.714227Z",
     "start_time": "2023-04-04T10:33:09.698685Z"
    }
   },
   "outputs": [],
   "source": [
    "# 选取真实光谱曲线函数\n",
    "# 找到n个最近邻\n",
    "# 按照理化值寻找最近邻\n",
    "def selectY(trainXset, trainYset, fakeY, n):# 真实y；生成y，需要的最近邻数量\n",
    "    minusY = trainYset - fakeY# 差值\n",
    "    minusY_2 = np.square(minusY)# 平方\n",
    "    nearestIndex = minusY_2.argsort()# 从小到大排序\n",
    "    nearestIndex = nearestIndex[0:n]\n",
    "    nearestY = trainYset[nearestIndex]\n",
    "    nearestX = trainXset[nearestIndex]\n",
    "    nearestX = nearestX.astype('float64')\n",
    "    return nearestX, nearestY# 输出n个最近邻的下标,最近邻X，最近邻Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baef215",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T11:03:37.914019Z",
     "start_time": "2023-04-04T11:03:37.894188Z"
    }
   },
   "outputs": [],
   "source": [
    "# 制造一个批次的生成器输入\n",
    "# 噪音（100）+二进制编码(100)+噪音（100）+二进制编码（100）+噪音（100）\n",
    "# 噪音以独热编码的形式放入\n",
    "def inputG(fakeY):\n",
    "    noiseUnit1 = tf.random.uniform([1, 200])# 生成一个200维的随机tensor\n",
    "    fakeY = fakeY*100\n",
    "    hundredPlace = int(fakeY/100)\n",
    "    tenPlace = int((fakeY%100)/10)\n",
    "    onePlace = int((fakeY%100)%10)\n",
    "    hundredOnehot = customize_Onehot(hundredPlace)\n",
    "    tenOnehot = customize_Onehot(tenPlace)\n",
    "    oneOnehot = customize_Onehot(onePlace)\n",
    "    hundredOnehot = hundredOnehot*6\n",
    "    tenOnehot = tenOnehot*3\n",
    "    oneOnehot = oneOnehot*1\n",
    "    hundredOnehot = np.array(hundredOnehot)\n",
    "    tenOnehot = np.array(tenOnehot)\n",
    "    oneOnehot = np.array(oneOnehot)\n",
    "    finalOnthot = np.concatenate((hundredOnehot, tenOnehot, oneOnehot),axis=None)\n",
    "    finalOnthot = finalOnthot.reshape(1,100)# 更改维度\n",
    "    finalOnthot = tf.convert_to_tensor(finalOnthot,dtype=tf.float32)# 改变数据类型(tensor,float32)\n",
    "    codeInput = tf.concat([finalOnthot, noiseUnit1[:,0:100], finalOnthot, noiseUnit1[:,100:200], finalOnthot],1)# 最后的G输入\n",
    "    return codeInput\n",
    "# 自定义十位数独热编码\n",
    "def customize_Onehot(data):\n",
    "    Onehot = []\n",
    "    for i in range(10):\n",
    "        if i == data:\n",
    "            Onehot.append(1)\n",
    "        else:\n",
    "            Onehot.append(0)\n",
    "    return Onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb1ae18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T11:03:38.333232Z",
     "start_time": "2023-04-04T11:03:38.309720Z"
    }
   },
   "outputs": [],
   "source": [
    "# 在训练之前，确定需要得到的y值(120个：超过难以实现)\n",
    "def generated_Sety(trainsetY):\n",
    "    sortY = np.sort(trainsetY)# 对理化值进行排序\n",
    "    generatedsetY = []\n",
    "    for i in range(120):\n",
    "        generatedY = sortY[i] + np.random.uniform(0,0.1)# 在每个y的基础上增加一个随机量\n",
    "        generatedsetY.append(generatedY)\n",
    "    return generatedsetY# 输出所要生成的y集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c44c5e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T11:03:38.714374Z",
     "start_time": "2023-04-04T11:03:38.689410Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_train(nearestX, z, i, j, alpha):\n",
    "    if i%30 == 0:# 每训练三十次，出一次训练图\n",
    "        # 在训练中占比高的设置为红色，低则为蓝色\n",
    "        generated_wave = generator(z)\n",
    "        generated_wave = np.array(generated_wave)\n",
    "        generated_wave = generated_wave.reshape(2500,1)\n",
    "        if alpha >= 0.5:# 第一个真实光谱在训练中的权重占比较高\n",
    "            print(\"这是第%s次训练，第%s张图\"%(j, int(i/30)))\n",
    "            plt.figure(figsize=(5.2, 3.1), dpi=300)# 设置画布\n",
    "            fonts = 8\n",
    "            plt.xlim(axis_x.min(),axis_x.max())\n",
    "            plt.ylim(-0.1, 1)\n",
    "            # 设置刻度字体大小\n",
    "            plt.xlabel('Wavelength (nm)', fontsize=fonts)\n",
    "            plt.ylabel('absorbance (AU)', fontsize=fonts)\n",
    "            plt.yticks(fontsize=fonts)\n",
    "            plt.xticks(fontsize=fonts)\n",
    "            #Padding between the figure edge and the edges of subplots, as a fraction of the font size.\n",
    "            #调整方格\n",
    "            plt.tight_layout(pad=0.25)\n",
    "            #网格线设置\n",
    "            plt.grid(True)\n",
    "            plt.plot(axis_x, nearestX[0], linewidth = 0.6, c = 'red')\n",
    "            plt.plot(axis_x, nearestX[1], linewidth = 0.6, c = 'blue')\n",
    "            plt.plot(axis_x, generated_wave, linewidth = 0.6, c = 'k')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"这是第%s次训练，第%s张图\"%(j, int(i/30)))\n",
    "            plt.figure(figsize=(5.2, 3.1), dpi=300)# 设置画布\n",
    "            fonts = 8\n",
    "            plt.xlim(axis_x.min(),axis_x.max())\n",
    "            plt.ylim(-0.1, 1)\n",
    "            # 设置刻度字体大小\n",
    "            plt.xlabel('Wavelength (nm)', fontsize=fonts)\n",
    "            plt.ylabel('absorbance (AU)', fontsize=fonts)\n",
    "            plt.yticks(fontsize=fonts)\n",
    "            plt.xticks(fontsize=fonts)\n",
    "            #Padding between the figure edge and the edges of subplots, as a fraction of the font size.\n",
    "            #调整方格\n",
    "            plt.tight_layout(pad=0.25)\n",
    "            #网格线设置\n",
    "            plt.grid(True)\n",
    "            plt.plot(axis_x, nearestX[0], linewidth = 0.6, c = 'blue')\n",
    "            plt.plot(axis_x, nearestX[1], linewidth = 0.6, c = 'red')\n",
    "            plt.plot(axis_x, generated_wave, linewidth = 0.6, c = 'k')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d7c525",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T11:03:39.107253Z",
     "start_time": "2023-04-04T11:03:39.075607Z"
    }
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(0.0002)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'D:\\Major_revision\\Major_RevisondataSet')\n",
    "x = np.load('trainx.npy',allow_pickle = True)\n",
    "y = np.load('trainy.npy',allow_pickle = True)\n",
    "# 将生成的y在真实y随机选择\n",
    "real_y = y\n",
    "generated_x = np.load('XfromX1.npy',allow_pickle = True)#如果文件路径末尾没有扩展名.npy，该扩展名会被自动加上\n",
    "generated_y = np.load('YfromY1.npy',allow_pickle = True)\n",
    "generated_y = generated_y.reshape(-1)\n",
    "x = np.vstack((x,generated_x))\n",
    "y = np.hstack((y,generated_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662d98a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T11:03:42.702132Z",
     "start_time": "2023-04-04T11:03:42.678957Z"
    }
   },
   "outputs": [],
   "source": [
    "generated_Yset = []\n",
    "generated_spectrumSet = []\n",
    "def Generated_spectrum():\n",
    "    global k\n",
    "    j = 1\n",
    "    for epoch in range(epochs):# 定义总训练次数\n",
    "        generatedSetY = generated_Sety(real_y)\n",
    "        if epoch >= 1:\n",
    "            generated_Yset.append(generatedSetY)\n",
    "        else:\n",
    "            generatedSetY = generatedSetY[0:100]\n",
    "        for generatedY in generatedSetY:\n",
    "            nearestX, nearestY = selectY(x, y, generatedY, 2)\n",
    "            alpha = Calculated_weight(generatedY, nearestY)# 计算权重\n",
    "            print(\"第%s次生成的光谱理化值：%s\"%(j, generatedY))\n",
    "            print('相近的光谱理化值：%s'%nearestY)\n",
    "            print('在训练中所占权重：%s'%alpha)\n",
    "            nearestX1 = nearestX[0].reshape(1,2500)\n",
    "            nearestX2 = nearestX[1].reshape(1,2500)\n",
    "            start = time.perf_counter()\n",
    "            for i in range(181):\n",
    "                codeInputG = inputG(generatedY)# 独热编码+噪声数据\n",
    "                with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "                    # 计算最外层损失\n",
    "                    outermost_loss1 = outermost_of_G(codeInputG)# G_最外层损失\n",
    "                    outermost_loss2 = outermost_of_D(nearestX, codeInputG, k)# D_最外层损失\n",
    "                    # 计算内层损失\n",
    "                    mesosphere_loss11 = mesosphere_of_G(codeInputG, discriminator1, discriminator4)# G_内层损失\n",
    "                    mesosphere_loss12 = mesosphere_of_D(codeInputG, nearestX1, discriminator1, discriminator4, k)# D_内层损失\n",
    "                    mesosphere_loss13 = mesosphere_of_D(codeInputG, nearestX2, discriminator1, discriminator4, k)# D_内层损失\n",
    "                    mesosphere_loss21 = mesosphere_of_G(codeInputG, discriminator2, discriminator3)# G_内层损失\n",
    "                    mesosphere_loss22 = mesosphere_of_D(codeInputG, nearestX1, discriminator2, discriminator3, k)# D_内层损失\n",
    "                    mesosphere_loss23 = mesosphere_of_D(codeInputG, nearestX2, discriminator2, discriminator3, k)# D_内层损失\n",
    "                    # 计算最里层损失\n",
    "                    Inner_loss = Innermost_L(nearestX1, nearestX2, codeInputG, discriminator5, generatedY, nearestY)\n",
    "                    # 总损失\n",
    "                    gen_loss = outermost_loss1 + mesosphere_loss11 + mesosphere_loss21 + Inner_loss\n",
    "                    disc_loss = outermost_loss2 + (mesosphere_loss12 + mesosphere_loss22)*alpha + (mesosphere_loss13 + mesosphere_loss23)*(1 - alpha) + Inner_loss \n",
    "                # 传入loss和模型参数，计算生成器的权值调整\n",
    "                gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "                # 传入loss和模型参数，计算判别器的权值调整\n",
    "                gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "                # 生成器的权值调整\n",
    "                generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "                # 判别器的权值调整\n",
    "                discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "                #更新k\n",
    "                goal,balance = global_process(nearestX, codeInputG,gamma)\n",
    "                k = tf.compat.v1.assign(k, tf.clip_by_value(k + lambda_k1 * balance, 0, 1))\n",
    "                image_train(nearestX, codeInputG, i, j, alpha)\n",
    "                if i/179 == 1:\n",
    "                    end = time.perf_counter()\n",
    "                    print('第%s次训练完成，花费时间：%s'%(j, end-start))\n",
    "                    if epoch >= 1:\n",
    "                        generation = generator(codeInputG)\n",
    "                        generated_spectrumSet.append(generation)\n",
    "                    j = j + 1\n",
    "        #输出goal\n",
    "        print('第%s次训练的全局得分：%s'%(epoch, goal))\n",
    "        #输出全局k\n",
    "        print('第%s次训练的k值：%s'%(epoch, k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a77597f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T11:04:58.032128Z",
     "start_time": "2023-04-04T11:03:43.106950Z"
    }
   },
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    start = time.perf_counter()\n",
    "    Generated_spectrum()\n",
    "    end = time.perf_counter()\n",
    "    print('训练总时长: %s Seconds'%(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将list转为numpy\n",
    "print(generated_Yset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "major_RevsionX2 = np.array(generated_spectrumSet).reshape(600,2500)\n",
    "major_RevsionY2 = np.array(generated_Yset).reshape(1,600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-dress",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'D:\\Major_revision\\Major_RevisondataSet')\n",
    "np.save('major_RevsionX2.npy',major_RevsionX2)#如果文件路径末尾没有扩展名.npy，该扩展名会被自动加上\n",
    "np.save('major_RevsionY2.npy',major_RevsionY2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-basic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-activity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-transfer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-humanity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
