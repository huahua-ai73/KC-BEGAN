{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743f4c99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T10:47:03.167641Z",
     "start_time": "2023-04-01T10:47:03.159690Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "#python在读写matlab文件时常用到scipy.io文件\n",
    "import scipy.io as sio\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense,BatchNormalization,LeakyReLU,Conv2DTranspose,Reshape,Conv2D,Dropout,Flatten,AveragePooling1D,Activation\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "import matplotlib\n",
    "from keras.models import Model\n",
    "import keras\n",
    "from scipy.signal import savgol_filter\n",
    "from numpy import *\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '/gpu:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5258dbd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T10:47:05.370983Z",
     "start_time": "2023-04-01T10:47:04.185096Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-action",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T10:47:06.970333Z",
     "start_time": "2023-04-01T10:47:06.922299Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.load('trainx.npy',allow_pickle = True)\n",
    "y = np.load('trainy.npy',allow_pickle = True)\n",
    "#定义真实光谱数据\n",
    "wave = x.reshape(-1,2500)\n",
    "wave = wave.astype('float64')\n",
    "print(wave.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-mortality",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T10:47:08.360568Z",
     "start_time": "2023-04-01T10:47:08.328561Z"
    }
   },
   "outputs": [],
   "source": [
    "P = np.load('axis_x.npy',allow_pickle =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-testimony",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T10:47:09.504464Z",
     "start_time": "2023-04-01T10:47:08.993478Z"
    }
   },
   "outputs": [],
   "source": [
    "#绘制频谱\n",
    "def PlotSpectrum(spec,axis_x):\n",
    "#创建画布\n",
    "    plt.figure(figsize=(5.2, 3.1), dpi=300)\n",
    "#np.arange()属于numpy模块。\n",
    "#生成一个从start（包含）到stop（不包含），以step为步长的序列。返回一个ndarray对象\n",
    "#spec.shape[1]为spec的第二个维度大小\n",
    "#np.arange()\n",
    "#1）一个参数时，参数值为终点，起点取默认值0，步长取默认值1。\n",
    "#2）两个参数时，第一个参数为起点，第二个参数为终点，步长取默认值1。\n",
    "#3）三个参数时，第一个参数为起点，第二个参数为终点，第三个参数为步长。其中步长支持小数\n",
    "    x = axis_x\n",
    "    for i in range(spec.shape[0]):\n",
    "        #取spec的第i行全部列作为y值\n",
    "        plt.plot(x, spec[i, :], linewidth=0.6)\n",
    "    fonts = 8\n",
    "    plt.xlim(x.min(),x.max())\n",
    "    plt.ylim(0, 1)\n",
    "    # 设置刻度字体大小\n",
    "    plt.xlabel('Wavelength (nm)', fontsize=fonts)\n",
    "    plt.ylabel('absorbance (AU)', fontsize=fonts)\n",
    "    plt.yticks(fontsize=fonts)\n",
    "    plt.xticks(fontsize=fonts)\n",
    "    #Padding between the figure edge and the edges of subplots, as a fraction of the font size.\n",
    "    #调整方格\n",
    "    plt.tight_layout(pad=0.3)\n",
    "    #网格线设置\n",
    "    plt.grid(True)\n",
    "    return plt\n",
    "PlotSpectrum(wave,P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-retreat",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T10:47:09.962956Z",
     "start_time": "2023-04-01T10:47:09.946955Z"
    }
   },
   "outputs": [],
   "source": [
    "#定义一些常数\n",
    "# Dataset中的buffer\n",
    "pre_buffer_size = 60\n",
    "# 批次大小（530/batch_size=程序要跑的次数）\n",
    "pre_batch_size = 15\n",
    "buffer_size = 60\n",
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-overall",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T10:47:18.336790Z",
     "start_time": "2023-04-01T10:47:18.328785Z"
    }
   },
   "outputs": [],
   "source": [
    "# 训练周期\n",
    "epochs = 6500\n",
    "# 100维的随机噪声\n",
    "noise_dim = 200\n",
    "# 除开理化值的噪声维度\n",
    "noise_dim_0 = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7033d23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T10:47:21.315807Z",
     "start_time": "2023-04-01T10:47:21.267593Z"
    }
   },
   "outputs": [],
   "source": [
    "#k的比例增益初始化为lambda_k=0.0001,用于不断调整k的值\n",
    "#经过20000次训练变成0.00001\n",
    "lambda_k1=0.0002\n",
    "lambda_k2=0.00001\n",
    "lambda_k3=0.000001\n",
    "#k的初值设为：0\n",
    "k = tf.Variable(0.005,dtype=tf.float64)\n",
    "#设置gamma(高多样性好)\n",
    "gamma = tf.Variable(0.7,dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f4b3c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T10:53:39.861611Z",
     "start_time": "2023-04-01T10:53:39.851638Z"
    }
   },
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    #顺序模型设置\n",
    "    model = tf.keras.Sequential()\n",
    "    #传入噪声数据\n",
    "    model.add(Dense(1000,input_shape=(noise_dim_0,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1800))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2500))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322e9516",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T10:53:40.588215Z",
     "start_time": "2023-04-01T10:53:40.469195Z"
    }
   },
   "outputs": [],
   "source": [
    "# from tensorflow.python.keras.utils.multi_gpu_utils import multi_gpu_model\n",
    "\n",
    "generator = generator_model()\n",
    "# generator = multi_gpu_model(generator,gpus=2)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecb9da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T11:43:33.104240Z",
     "start_time": "2023-04-01T11:43:33.093229Z"
    }
   },
   "outputs": [],
   "source": [
    "#定义判别器\n",
    "def discriminator_model():\n",
    "    #顺序模型\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(1800,input_shape=(2500,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1000))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(500))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1000))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1800))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2500))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714c7cbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T11:43:33.701325Z",
     "start_time": "2023-04-01T11:43:33.511639Z"
    }
   },
   "outputs": [],
   "source": [
    "discriminator = discriminator_model()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d72542",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T11:37:20.901724Z",
     "start_time": "2023-04-01T11:37:20.890715Z"
    }
   },
   "outputs": [],
   "source": [
    "discriminator.get_layer(index=11).output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbd7cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d88429",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T11:44:05.775943Z",
     "start_time": "2023-04-01T11:44:05.752007Z"
    }
   },
   "outputs": [],
   "source": [
    "# layer_name = 'leaky_re_lu_11' #获取层的名称\n",
    "noiseTest = tf.random.normal([batch_size, noise_dim_0])\n",
    "# generator1 = Model(inputs=generator.input, \n",
    "#                                  outputs=generator.get_layer(index=2).output)# 输出为1800\n",
    "\n",
    "discriminator1 = Model(inputs=discriminator.input, \n",
    "                                 outputs=discriminator.get_layer(index=2).output)# 输出为1800，第2层\n",
    "\n",
    "discriminator2 = Model(inputs=discriminator.input, \n",
    "                                 outputs=discriminator.get_layer(index=5).output)# 输出为1800，第8层\n",
    "\n",
    "discriminator3 = Model(inputs=discriminator.input, \n",
    "                                 outputs=discriminator.get_layer(index=11).output)# 输出为1800，第8层\n",
    "\n",
    "discriminator4 = Model(inputs=discriminator.input, \n",
    "                                 outputs=discriminator.get_layer(index=14).output)# 输出为1800，第8层\n",
    "\n",
    "# intermediate_output = intermediate_layer_model.predict(noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4ffec5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T11:54:04.944933Z",
     "start_time": "2023-04-01T11:54:04.926943Z"
    }
   },
   "outputs": [],
   "source": [
    "discriminator1(wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597c9880",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T11:54:06.373110Z",
     "start_time": "2023-04-01T11:54:06.349174Z"
    }
   },
   "outputs": [],
   "source": [
    "discriminator2(wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff8189c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T11:54:07.526079Z",
     "start_time": "2023-04-01T11:54:07.501579Z"
    }
   },
   "outputs": [],
   "source": [
    "discriminator3(wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef3078a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T11:54:11.824627Z",
     "start_time": "2023-04-01T11:54:11.792126Z"
    }
   },
   "outputs": [],
   "source": [
    "discriminator4(wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63121f7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T11:44:58.414267Z",
     "start_time": "2023-04-01T11:44:58.381425Z"
    }
   },
   "outputs": [],
   "source": [
    "# MSG-GAN多尺度梯度生成式对抗网络\n",
    "def L1(wave, D1, D2):# D1:wave的编码部分；D2：wave的解码部分\n",
    "    #通过判别器得到D_ture\n",
    "    D_output1 = D1(wave)# D1:1800\n",
    "    D_output2 = D2(wave)# D2:1800\n",
    "    D_output1 = tf.cast(D_output1,dtype=tf.float64)\n",
    "    D_output2 = tf.cast(D_output2,dtype=tf.float64)\n",
    "    #BEGAN的D的损失函数的前半部分(L(x))\n",
    "    L1_loss = tf.reduce_mean(tf.abs(D_output1 - D_output2))\n",
    "    L1_loss = tf.cast(L1_loss,dtype=tf.float64)\n",
    "    return L1_loss \n",
    "def L2(noise, G, D1, D2):# D1:wave的编码部分；D2：wave的解码部分\n",
    "    G_output = G(noise)# G:2500\n",
    "    G_output = tf.cast(G_output,dtype=tf.float64)    \n",
    "    D_output1 = D1(G_output)# D1:1800\n",
    "    D_output1 = tf.cast(D_output1,dtype=tf.float64)\n",
    "    D_output2 = D2(G_output)# D2:1800\n",
    "    D_output2 = tf.cast(D_output2,dtype=tf.float64)\n",
    "    #作差-取绝对-求平均值(L(G(x)))\n",
    "    L2_loss = tf.reduce_mean(tf.abs(D_output2 - D_output1))\n",
    "    L2_loss = tf.cast(L2_loss,dtype=tf.float64)\n",
    "    return L2_loss \n",
    "def L3(wave, D):\n",
    "    #通过判别器得到D_ture\n",
    "    D_output = D(wave)\n",
    "    D_output = tf.cast(D_output,dtype=tf.float64)\n",
    "    #BEGAN的D的损失函数的前半部分(L(x))\n",
    "    L3_loss = tf.reduce_mean(tf.abs(D_output - wave))\n",
    "    L3_loss = tf.cast(L3_loss,dtype=tf.float64)\n",
    "    return L3_loss \n",
    "def L4(noise, G, D):# D1:wave的编码部分；D2：wave的解码部分\n",
    "    G_output = G(noise)# G:完整的generator\n",
    "    G_output = tf.cast(G_output,dtype=tf.float64)    \n",
    "    D_output = D(G_output)# 编码到指定尺寸\n",
    "    D_output = tf.cast(D_output,dtype=tf.float64)\n",
    "    #作差-取绝对-求平均值(L(G(x)))\n",
    "    L4_loss = tf.reduce_mean(tf.abs(G_output - D_output))\n",
    "    L4_loss = tf.cast(L4_loss,dtype=tf.float64)\n",
    "    return L4_loss \n",
    "#定义生成器损失\n",
    "def LG(noise, G1, D1, D2):# D: 适配G尺寸的自编码器\n",
    "    G_loss = L2(noise, G1, D1, D2)\n",
    "    return G_loss\n",
    "# \n",
    "def LG1(noise, G, D):# 原始损失函数\n",
    "    G_loss = L4(noise, G, D)\n",
    "    return G_loss\n",
    "def LD(wave, noise, k, G, D1, D2):# D1:wave的编码部分；D2：wave的解码部分；\n",
    "    loss1 = L1(wave, D1, D2)\n",
    "    loss2 = L2(noise, G, D1, D2)\n",
    "    total_loss = loss1 - k*loss2\n",
    "    return total_loss\n",
    "# \n",
    "def LD1(wave, noise, k, G, D):# 原始损失函数\n",
    "    loss1 = L3(wave, D)\n",
    "    loss2 = L4(noise, G, D)\n",
    "    total_loss = loss1 - k*loss2\n",
    "    return total_loss\n",
    "#更新k参数\n",
    "def update_k():\n",
    "    global k\n",
    "    k = tf.compat.v1.assign(k, tf.clip_by_value(k + lambda_k * balance, 0, 1))\n",
    "#定义损失函数\n",
    "#预定义L(G(x))\n",
    "def L_G(noise):\n",
    "    #通过生成器生成的值G_fake\n",
    "    G_fake = generator(noise)\n",
    "    G_fake = tf.cast(G_fake,dtype=tf.float64)\n",
    "    #通过判别器得到的结果D_fake\n",
    "    D_fake = discriminator(G_fake)\n",
    "    D_fake = tf.cast(D_fake,dtype=tf.float64)\n",
    "    #作差-取绝对-求平均值(L(G(x)))\n",
    "    L_G = tf.reduce_mean(tf.abs(G_fake-D_fake))\n",
    "    return L_G\n",
    "#预定义L(x)\n",
    "def L(ture_wave):\n",
    "    #通过判别器得到D_ture\n",
    "    D_ture = discriminator(ture_wave)\n",
    "    D_ture = tf.cast(D_ture,dtype=tf.float64)\n",
    "    #BEGAN的D的损失函数的前半部分(L(x))\n",
    "    L_x = tf.reduce_mean(tf.abs(ture_wave-D_ture))\n",
    "    return L_x   \n",
    "#定义生成器损失\n",
    "def G_LOSS(noise):\n",
    "    G_loss = L_G(noise)\n",
    "    return G_loss\n",
    "def D_LOSS(ture_wave,noise,k):\n",
    "    L1 = L(ture_wave)\n",
    "    LG1 = L_G(noise)\n",
    "    total_loss = L1 - k*LG1\n",
    "    return total_loss\n",
    "#更新k参数\n",
    "def update_k():\n",
    "    global k\n",
    "    # print('k值为：%s'%k)\n",
    "    k = tf.compat.v1.assign(k, tf.clip_by_value(k + lambda_k * balance, 0, 1))\n",
    "#定义总体进度函数\n",
    "def global_pro(ture_wave,noise,gamma):\n",
    "    L2 = L(ture_wave)\n",
    "    LG2 = L_G(noise)\n",
    "    balance = gamma*L2 - LG2\n",
    "    balance = tf.cast(balance,dtype=tf.float64)\n",
    "    #总体进度定义\n",
    "    global_goal = L2 + tf.abs(balance)\n",
    "    return global_goal,balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d9dfaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T11:44:59.910342Z",
     "start_time": "2023-04-01T11:44:59.890359Z"
    }
   },
   "outputs": [],
   "source": [
    "#分别定义两个网络，判别器和生成器优化器\n",
    "generator_optimizer = tf.keras.optimizers.Adam(0.0002)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(0.0002)\n",
    "#切分数据集\n",
    "pre_train_dataset = tf.data.Dataset.from_tensor_slices(wave).shuffle(pre_buffer_size).batch(pre_batch_size)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(wave).shuffle(buffer_size).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9c05c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T11:45:00.888899Z",
     "start_time": "2023-04-01T11:45:00.872362Z"
    }
   },
   "outputs": [],
   "source": [
    "#提前训练D\n",
    "#定义提前训练损失函数\n",
    "def pretrainLoss(wave, D):\n",
    "    #损失函数就是L(x)\n",
    "    treated_D = L(wave)\n",
    "    return treated_D\n",
    "#需要记录训练损失的变化\n",
    "Epochs = 200\n",
    "def Pre_train_D(dataset,Epochs):\n",
    "    summary_writer = tf.summary.create_file_writer('D:/Pre_train')\n",
    "    # 训练epochs周期\n",
    "    for epoch in range(Epochs):\n",
    "        # 每次获得一个批次的真实图片传入train_step函数进行训练\n",
    "        for wave_batch in dataset:\n",
    "            with tf.GradientTape() as DISC_tape:\n",
    "                #计算判别器LOSS（只输入真实数据）\n",
    "                disc_loss = pretrainLoss(wave_batch, discriminator)\n",
    "            # 传入loss和模型参数，计算判别器的权值调整\n",
    "            gradients_of_discriminator = DISC_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "            # 判别器的权值调整\n",
    "            discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar('loss',disc_loss,step=epoch)\n",
    "        if epoch%20 ==0:\n",
    "            print(disc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb98490",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T11:45:08.983018Z",
     "start_time": "2023-04-01T11:45:01.481269Z"
    }
   },
   "outputs": [],
   "source": [
    "Start = time.perf_counter()\n",
    "Pre_train_D(pre_train_dataset,Epochs)\n",
    "End = time.perf_counter()\n",
    "print('Running time: %s Seconds'%(End-Start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88eeb19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-31T13:08:48.448916Z",
     "start_time": "2023-03-31T13:08:48.334230Z"
    }
   },
   "outputs": [],
   "source": [
    "generator.save('MSG_pregeneratorLast.h5')\n",
    "discriminator.save('MSG_prediscriminatorLast.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3797cb64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T11:56:17.349250Z",
     "start_time": "2023-04-01T11:56:17.340300Z"
    }
   },
   "outputs": [],
   "source": [
    "p = P\n",
    "# 生成图片并保存显示\n",
    "def generate_and_save_images(model, test_input):\n",
    "    # 注意training设定为False，所有层都在预测模式下运行\n",
    "    predictions = model(test_input, training=False)\n",
    "    # 显示图片\n",
    "    #建立横轴\n",
    "    #设置点\n",
    "    predictions = np.array(predictions)\n",
    "    predictions = predictions.reshape(120,x.shape[1])\n",
    "    for i in range(predictions.shape[0]):\n",
    "        #取spec的第i行全部列作为y值\n",
    "        plt.plot(p, predictions[i, :], linewidth=0.6)\n",
    "    fonts = 8\n",
    "    fonts = 8\n",
    "    plt.xlim(p.min(),p.max())\n",
    "    # 设置刻度字体大小\n",
    "    plt.xlabel('Wavelength (nm)', fontsize=fonts)\n",
    "    plt.ylabel('Absorbance (AU)', fontsize=fonts)\n",
    "    plt.yticks(fontsize=fonts)\n",
    "    plt.xticks(fontsize=fonts)\n",
    "    #Padding between the figure edge and the edges of subplots, as a fraction of the font size.\n",
    "    # 显示图片\n",
    "    plt.show()\n",
    "def generate_and_save_images_b(model, i, test_input):\n",
    "    # 注意training设定为False，所有层都在预测模式下运行\n",
    "    predictions = model(test_input, training=False)\n",
    "    # 显示图片\n",
    "    #建立横轴\n",
    "    #设置点\n",
    "    predictions = np.array(predictions)\n",
    "    predictions = predictions.reshape(x.shape[1],1)\n",
    "    fonts = 8\n",
    "    plt.xlim(p.min(),p.max())\n",
    "    # 设置刻度字体大小\n",
    "    plt.xlabel('Wavelength (nm)', fontsize=fonts)\n",
    "    plt.ylabel('Absorbance (AU)', fontsize=fonts)\n",
    "    plt.yticks(fontsize=fonts)\n",
    "    plt.xticks(fontsize=fonts)\n",
    "    #Padding between the figure edge and the edges of subplots, as a fraction of the font size.\n",
    "    #调整方格\n",
    "    plt.tight_layout(pad=0.3)\n",
    "    #网格线设置\n",
    "    plt.plot(P,predictions,linewidth=0.5,c = 'k')\n",
    "    # 显示图片\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa415371",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T11:56:17.913168Z",
     "start_time": "2023-04-01T11:56:17.889194Z"
    }
   },
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "process = []\n",
    "def train_0(dataset, epochs):\n",
    "    # 训练epochs周期\n",
    "    #将k值变化放到K文件中\n",
    "    summary_K = tf.summary.create_file_writer('D:/K')\n",
    "    #将dis_loss和gen_loss放在LOSS中\n",
    "    summary_LOSS = tf.summary.create_file_writer('D:/LOSS')\n",
    "    #定义全局k\n",
    "    global k\n",
    "    goal_container = []\n",
    "    num_patience = 0\n",
    "    for epoch in range(epochs):\n",
    "        # 每次获得一个批次的真实图片传入train_step函数进行训练\n",
    "        #这里应该根据传入的epoch，设置一个梯度的训练参数\n",
    "        #当epoch小于2000次时，使用\n",
    "        if epoch<=500:\n",
    "            for wave_batch in dataset:\n",
    "                # 生成一个批次的随机数，这个随机数用于模型训练\n",
    "                noise = tf.random.normal([batch_size, noise_dim_0])   #输出goal全局得分\n",
    "                goal,balance = global_pro(wave_batch, noise, gamma)\n",
    "                #输出goal\n",
    "                print('全局得分：%s'%goal)\n",
    "                #输出全局k\n",
    "                print('k:%s'%k)\n",
    "                goal = float(goal)\n",
    "                # print(goal)\n",
    "                goal_container.append(goal)\n",
    "                # 固定写法，使用tf.GradientTape()来计算梯度\n",
    "                with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "                    # 计算生成器loss\n",
    "                    gen_loss1 = LG1(noise, generator, discriminator)\n",
    "                    gen_loss2 = LG(noise, generator, discriminator1, discriminator4)\n",
    "                    gen_loss3 = LG(noise, generator, discriminator2, discriminator3)\n",
    "                    gen_loss = gen_loss1 + gen_loss2 + gen_loss3\n",
    "                    # 计算判别器loss\n",
    "                    disc_loss1 = LD1(wave_batch, noise, k, generator, discriminator)\n",
    "                    disc_loss2 = LD(wave_batch, noise, k, generator, discriminator1, discriminator4)\n",
    "                    disc_loss3 = LD(wave_batch, noise, k, generator, discriminator2, discriminator3)\n",
    "                    disc_loss = disc_loss1 + disc_loss2 + disc_loss3\n",
    "                # 传入loss和模型参数，计算生成器的权值调整\n",
    "                gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "                # 传入loss和模型参数，计算判别器的权值调整\n",
    "                gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "                # 生成器的权值调整\n",
    "                generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "                # 判别器的权值调整\n",
    "                discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "                #更新k\n",
    "                k = tf.compat.v1.assign(k, tf.clip_by_value(k + lambda_k1 * balance, 0, 1))\n",
    "        elif 500<epoch<=6000:\n",
    "            for wave_batch in dataset:\n",
    "                # 生成一个批次的随机数，这个随机数用于模型训练\n",
    "                noise = tf.random.normal([batch_size, noise_dim_0])\n",
    "                #输出goal全局得分\n",
    "                goal,balance = global_pro(wave_batch,noise,gamma)\n",
    "                #输出goal\n",
    "                print('全局得分：%s'%goal)\n",
    "                print('k:%s'%k)\n",
    "                goal = float(goal)\n",
    "                # print(goal)\n",
    "                goal_container.append(goal)\n",
    "                # 固定写法，使用tf.GradientTape()来计算梯度\n",
    "                with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "                    # 计算生成器loss\n",
    "                    gen_loss1 = LG1(noise, generator, discriminator)\n",
    "                    gen_loss2 = LG(noise, generator, discriminator1, discriminator4)\n",
    "                    gen_loss3 = LG(noise, generator, discriminator2, discriminator3)\n",
    "                    gen_loss = gen_loss1 + gen_loss2 + gen_loss3\n",
    "                    # 计算判别器loss\n",
    "                    disc_loss1 = LD1(wave_batch, noise, k, generator, discriminator)\n",
    "                    disc_loss2 = LD(wave_batch, noise, k, generator, discriminator1, discriminator4)\n",
    "                    disc_loss3 = LD(wave_batch, noise, k, generator, discriminator2, discriminator3)\n",
    "                    disc_loss = disc_loss1 + disc_loss2 + disc_loss3\n",
    "                # 传入loss和模型参数，计算生成器的权值调整\n",
    "                gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "                # 传入loss和模型参数，计算判别器的权值调整\n",
    "                gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "                # 生成器的权值调整\n",
    "                generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "                # 判别器的权值调整\n",
    "                discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "                #更新k\n",
    "                k = tf.compat.v1.assign(k, tf.clip_by_value(k + lambda_k2 * balance, 0, 1))  \n",
    "        with summary_K.as_default():\n",
    "            tf.summary.scalar('k',k,step=epoch)\n",
    "        with summary_LOSS.as_default():\n",
    "            tf.summary.scalar('gen_loss',gen_loss,step=epoch)\n",
    "            tf.summary.scalar('dis_loss',disc_loss,step=epoch)\n",
    "        # 显示和保存图片\n",
    " \n",
    "        print('第%s次训练'%epoch)\n",
    "        print('xxxxxxxxxxxxxxxxxxxxxxxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a661cae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T11:56:18.646602Z",
     "start_time": "2023-04-01T11:56:18.606675Z"
    }
   },
   "outputs": [],
   "source": [
    "test_input = tf.random.normal([120, noise_dim_0])\n",
    "\n",
    "# # 需要将数据平滑，再进行下一步迭代\n",
    "# b = savgol_filter(b, 41, 3, mode = \"nearest\")\n",
    "# b = np.array(b)\n",
    "# b = b.reshape(2500,1)\n",
    "\n",
    "turning_point(test_input[0:1], generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6067a14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T11:56:34.944649Z",
     "start_time": "2023-04-01T11:56:21.432148Z"
    }
   },
   "outputs": [],
   "source": [
    "# 模型训练 \n",
    "#记录运行时间\n",
    "start = time.perf_counter()\n",
    "train_0(train_dataset, epochs)\n",
    "end = time.perf_counter()\n",
    "print('Running time: %s Seconds'%(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c22be9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-31T14:19:45.579790Z",
     "start_time": "2023-03-31T14:19:45.518546Z"
    }
   },
   "outputs": [],
   "source": [
    "noise_test = tf.random.normal([600, noise_dim_0])\n",
    "outPut = generator(noise_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8efbe5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-31T14:19:49.260811Z",
     "start_time": "2023-03-31T14:19:46.100691Z"
    }
   },
   "outputs": [],
   "source": [
    "PlotSpectrum(outPut,P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-carter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-31T14:15:29.619762Z",
     "start_time": "2023-03-31T14:15:29.505566Z"
    }
   },
   "outputs": [],
   "source": [
    "generator.save('MSG_generatorLast.h5')\n",
    "discriminator.save('MSG_discriminatorLast.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f7bf39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-russia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
